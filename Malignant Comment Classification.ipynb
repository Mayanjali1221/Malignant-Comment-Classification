{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84d262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Importing all necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b182857",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('../input/malignant-comment-classification/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf04ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv('../input/malignant-comment-classification/test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0331de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train shape is ',train.shape)\n",
    "print('test shape is ',test.shape)\n",
    "print('test info',test.info)\n",
    "\n",
    "\n",
    "print('train info',train.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3616c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train data Set descriptin',train.describe())\n",
    "print('test data Set descriptin',test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a768276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking null values\n",
    "print(train.isnull().sum())\n",
    "print(sns.heatmap(train.isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95848bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## checking correlation in dataset\n",
    "print(train.corr())\n",
    "print(sns.heatmap(train.corr()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65064107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the skewness for the features:\n",
    "train.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076c2bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "col=['malignant','highly_malignant','loathe','rude','abuse','threat']\n",
    "for i in col:\n",
    "    print(i)\n",
    "    print(\"\\n\")\n",
    "    print(train[i].value_counts())\n",
    "    sns.countplot(train[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d588e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.corpus import  stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cd9c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['length'] = train['comment_text'].str.len()\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b262baeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all messages to lower case\n",
    "train['comment_text'] = train['comment_text'].str.lower()\n",
    "\n",
    "# Replace email addresses with 'email'\n",
    "train['comment_text'] = train['comment_text'].str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$',\n",
    "                                 'emailaddress')\n",
    "\n",
    "# Replace URLs with 'webaddress'\n",
    "train['comment_text'] = train['comment_text'].str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$',\n",
    "                                  'webaddress')\n",
    "\n",
    "# Replace money symbols with 'moneysymb' (£ can by typed with ALT key + 156)\n",
    "train['comment_text'] = train['comment_text'].str.replace(r'£|\\$', 'dollers')\n",
    "    \n",
    "# Replace 10 digit phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\n",
    "train['comment_text'] = train['comment_text'].str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$',\n",
    "                                  'phonenumber')\n",
    "\n",
    "    \n",
    "# Replace numbers with 'numbr'\n",
    "train['comment_text'] = train['comment_text'].str.replace(r'\\d+(\\.\\d+)?', 'numbr')\n",
    "\n",
    "\n",
    "train['comment_text'] = train['comment_text'].apply(lambda x: ' '.join(\n",
    "    term for term in x.split() if term not in string.punctuation))\n",
    "\n",
    "stop_words = set(stopwords.words('english') + ['u', 'ü', 'ur', '4', '2', 'im', 'dont', 'doin', 'ure'])\n",
    "train['comment_text'] = train['comment_text'].apply(lambda x: ' '.join(\n",
    "    term for term in x.split() if term not in stop_words))\n",
    "\n",
    "lem=WordNetLemmatizer()\n",
    "train['comment_text'] = train['comment_text'].apply(lambda x: ' '.join(\n",
    " lem.lemmatize(t) for t in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34646cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['clean_length'] = train.comment_text.str.len()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fec0468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total length removal\n",
    "print ('Origian Length', train.length.sum())\n",
    "print ('Clean Length', train.clean_length.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad5441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting sense of loud words which are offensive\n",
    "from wordcloud import WordCloud\n",
    "hams = train['comment_text'][train['malignant']==1]\n",
    "spam_cloud = WordCloud(width=600,height=400,background_color='black',max_words=50).generate(' '.join(hams))\n",
    "plt.figure(figsize=(10,8),facecolor='k')\n",
    "plt.imshow(spam_cloud)\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667fe4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report,roc_curve,roc_auc_score,auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be965878",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_target = ['malignant','highly_malignant','rude','threat','abuse','loathe']\n",
    "df_distribution = train[cols_target].sum()\\\n",
    "                            .to_frame()\\\n",
    "                            .rename(columns={0: 'count'})\\\n",
    "                            .sort_values('count')\n",
    "\n",
    "df_distribution.plot.pie(y='count',\n",
    "                                      title='Label distribution over comments',\n",
    "                                      figsize=(5, 5))\\\n",
    "                            .legend(loc='center left', bbox_to_anchor=(1.3, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b1f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data = train[cols_target]\n",
    "\n",
    "train['bad'] =train[cols_target].sum(axis =1)\n",
    "print(train['bad'].value_counts())\n",
    "train['bad'] = train['bad'] > 0 \n",
    "train['bad'] = train['bad'].astype(int)\n",
    "print(train['bad'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473f9f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.countplot(x=\"bad\" , data = train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d29c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Convert text into vectors using TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf_vec = TfidfVectorizer(max_features = 10000, stop_words='english')\n",
    "features = tf_vec.fit_transform(train['comment_text'])\n",
    "x = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ae3b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e30deea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dc1466",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train['bad']\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=56,test_size=.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b4f18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64df94f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression\n",
    "LG = LogisticRegression(C=1, max_iter = 3000)\n",
    "\n",
    "LG.fit(x_train, y_train)\n",
    "\n",
    "y_pred_train = LG.predict(x_train)\n",
    "print('Training accuracy is {}'.format(accuracy_score(y_train, y_pred_train)))\n",
    "y_pred_test = LG.predict(x_test)\n",
    "print('Test accuracy is {}'.format(accuracy_score(y_test,y_pred_test)))\n",
    "print(confusion_matrix(y_test,y_pred_test))\n",
    "print(classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9863106f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier\n",
    "DT = DecisionTreeClassifier()\n",
    "\n",
    "DT.fit(x_train, y_train)\n",
    "y_pred_train = DT.predict(x_train)\n",
    "print('Training accuracy is {}'.format(accuracy_score(y_train, y_pred_train)))\n",
    "y_pred_test = DT.predict(x_test)\n",
    "print('Test accuracy is {}'.format(accuracy_score(y_test,y_pred_test)))\n",
    "print(confusion_matrix(y_test,y_pred_test))\n",
    "print(classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15365b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestClassifier\n",
    "RF = RandomForestClassifier()\n",
    "\n",
    "RF.fit(x_train, y_train)\n",
    "y_pred_train = RF.predict(x_train)\n",
    "print('Training accuracy is {}'.format(accuracy_score(y_train, y_pred_train)))\n",
    "y_pred_test = RF.predict(x_test)\n",
    "print('Test accuracy is {}'.format(accuracy_score(y_test,y_pred_test)))\n",
    "print(confusion_matrix(y_test,y_pred_test))\n",
    "print(classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc940bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost\n",
    "import xgboost\n",
    "xgb = xgboost.XGBClassifier()\n",
    "xgb.fit(x_train, y_train)\n",
    "y_pred_train = xgb.predict(x_train)\n",
    "print('Training accuracy is {}'.format(accuracy_score(y_train, y_pred_train)))\n",
    "y_pred_test = xgb.predict(x_test)\n",
    "print('Test accuracy is {}'.format(accuracy_score(y_test,y_pred_test)))\n",
    "print(confusion_matrix(y_test,y_pred_test))\n",
    "print(classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4c2cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoostClassifier\n",
    "ada=AdaBoostClassifier(n_estimators=100)\n",
    "ada.fit(x_train, y_train)\n",
    "y_pred_train = ada.predict(x_train)\n",
    "print('Training accuracy is {}'.format(accuracy_score(y_train, y_pred_train)))\n",
    "y_pred_test = ada.predict(x_test)\n",
    "print('Test accuracy is {}'.format(accuracy_score(y_test,y_pred_test)))\n",
    "print(confusion_matrix(y_test,y_pred_test))\n",
    "print(classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdad4524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors=9)\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred_train = knn.predict(x_train)\n",
    "print('Training accuracy is {}'.format(accuracy_score(y_train, y_pred_train)))\n",
    "y_pred_test = knn.predict(x_test)\n",
    "print('Test accuracy is {}'.format(accuracy_score(y_test,y_pred_test)))\n",
    "print(confusion_matrix(y_test,y_pred_test))\n",
    "print(classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f775a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier\n",
    "RF = RandomForestClassifier()\n",
    "RF.fit(x_train, y_train)\n",
    "y_pred_train = RF.predict(x_train)\n",
    "print('Training accuracy is {}'.format(accuracy_score(y_train, y_pred_train)))\n",
    "y_pred_test = RF.predict(x_test)\n",
    "print('Test accuracy is {}'.format(accuracy_score(y_test,y_pred_test)))\n",
    "cvs=cross_val_score(RF, x, y, cv=10, scoring='accuracy').mean()\n",
    "print('cross validation score :',cvs*100)\n",
    "print(confusion_matrix(y_test,y_pred_test))\n",
    "print(classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a2a9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the graph which tells us about the area under curve , more the area under curve more will be the better prediction\n",
    "# model is performing good :\n",
    "fpr,tpr,thresholds=roc_curve(y_test,y_pred_test)\n",
    "roc_auc=auc(fpr,tpr)\n",
    "plt.plot([0,1],[1,0],'k--')\n",
    "plt.plot(fpr,tpr,label = 'RF Classifier')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('RF CLASSIFIER')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95afd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "eli5.show_weights(RF,vec = tf_vec, top = 15)  #random forest\n",
    "# will give you top 15 features or words  which makes a comment toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5885183",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data =tf_vec.fit_transform(test['comment_text'])\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093763af",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=RF.predict(test_data)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb22e651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(RF,\"malig.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
